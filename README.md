# STOR390project2

This is a project for a statistics class (STOR 390 w/ Giacomazzo). Our job is to predict games (binary W-L), spread, and total points for a handful of college football games over the last two weeks of the season. The webscraping Jupyter nb gets team schedules from a few websites, and also grabs data from the sports-reference Python API. I also just added a "team_distances" notebook that calculates distance between teams by webscraping from wiki and a mapping website. I would've used a maps API to make it easy on myself, but Google makes you pay to use it with no free queries. Oh well. Distance might be worth adding as a variable because rivalries like Duke-UNC, where the two schools are 8 miles apart, can be notoriously wonky games. There are some rivalries like ND-USC where the teams aren't close, so the assumption isn't always correct. Still, I think it mostly holds true. 
I clean and rearrange a good portion the data in R, not only because dplyr/tidyverse are great, but also to keep consistent with team work. The stats department here at UNC likes to use and teach R in most classes. The R notebook also contains some very simple models: a baseline logistic regression and xgboost binary classifier. Neither are particularly great (55% and 75%, respectively). The xgboost Jupyter notebooks predict total and spread--they seem to work decently well. The win_loss_classifier is a neural net built in Keras, and gets around 83% accuracy. 
